#!/usr/bin/env python3
"""
Script to create a proper Jupyter notebook file
"""

import json

# Create the notebook structure
notebook = {
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Harvey Analytics - Data Quality Analysis\n",
                "\n",
                "This notebook provides a comprehensive analysis of data quality issues in the Harvey Analytics platform.\n",
                "It analyzes actual data to identify real issues, not imagined ones.\n",
                "\n",
                "## Overview\n",
                "- **Data Completeness**: Check for missing values\n",
                "- **Data Consistency**: Validate data ranges and formats\n",
                "- **Business Logic**: Verify business rules\n",
                "- **Anomaly Detection**: Identify statistical outliers\n",
                "- **Visualizations**: Create charts for analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import required libraries\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import plotly.express as px\n",
                "import plotly.graph_objects as go\n",
                "from plotly.subplots import make_subplots\n",
                "import warnings\n",
                "from datetime import datetime\n",
                "from pathlib import Path\n",
                "import sys\n",
                "\n",
                "# Add utils to path\n",
                "sys.path.append('..')\n",
                "from utils.data_loader import load_harvey_data, get_data_summary, print_data_summary\n",
                "\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Set plotting style\n",
                "plt.style.use('seaborn-v0_8')\n",
                "sns.set_palette(\"husl\")\n",
                "\n",
                "print(\"‚úÖ Libraries imported successfully\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load and Explore Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the data\n",
                "users_df, firms_df, events_df = load_harvey_data()\n",
                "\n",
                "print(\"üìä Data loaded successfully!\")\n",
                "print(f\"Users: {len(users_df)} records\")\n",
                "print(f\"Firms: {len(firms_df)} records\")\n",
                "print(f\"Events: {len(events_df)} records\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display data summaries\n",
                "print(\"üë• Users Data Summary:\")\n",
                "print(users_df.info())\n",
                "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
                "\n",
                "print(\"üè¢ Firms Data Summary:\")\n",
                "print(firms_df.info())\n",
                "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
                "\n",
                "print(\"üìà Events Data Summary:\")\n",
                "print(events_df.info())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Data Completeness Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "def analyze_completeness(users_df, firms_df, events_df):\n",
                "    \"\"\"Analyze data completeness issues.\"\"\"\n",
                "    print(\"\\nüîç Data Completeness Analysis\")\n",
                "    print(\"=\" * 50)\n",
                "    \n",
                "    # Users missing values\n",
                "    users_missing = users_df.isnull().sum()\n",
                "    users_missing_pct = (users_missing / len(users_df)) * 100\n",
                "    \n",
                "    print(f\"\\nüë• Users Missing Values:\")\n",
                "    for col, missing_count in users_missing.items():\n",
                "        if missing_count > 0:\n",
                "            pct = (missing_count / len(users_df)) * 100\n",
                "            print(f\"   {col}: {missing_count} records ({pct:.1f}%)\")\n",
                "        else:\n",
                "            print(f\"   {col}: No missing values\")\n",
                "    \n",
                "    # Firms missing values\n",
                "    firms_missing = firms_df.isnull().sum()\n",
                "    firms_missing_pct = (firms_missing / len(firms_df)) * 100\n",
                "    \n",
                "    print(f\"\\nüè¢ Firms Missing Values:\")\n",
                "    for col, missing_count in firms_missing.items():\n",
                "        if missing_count > 0:\n",
                "            pct = (missing_count / len(firms_df)) * 100\n",
                "            print(f\"   {col}: {missing_count} records ({pct:.1f}%)\")\n",
                "        else:\n",
                "            print(f\"   {col}: No missing values\")\n",
                "    \n",
                "    # Events missing values\n",
                "    events_missing = events_df.isnull().sum()\n",
                "    events_missing_pct = (events_missing / len(events_df)) * 100\n",
                "    \n",
                "    print(f\"\\nüìà Events Missing Values:\")\n",
                "    for col, missing_count in events_missing.items():\n",
                "        if missing_count > 0:\n",
                "            pct = (missing_count / len(events_df)) * 100\n",
                "            print(f\"   {col}: {missing_count} records ({pct:.1f}%)\")\n",
                "        else:\n",
                "            print(f\"   {col}: No missing values\")\n",
                "    \n",
                "    return {\n",
                "        'users_missing': users_missing,\n",
                "        'firms_missing': firms_missing,\n",
                "        'events_missing': events_missing\n",
                "    }\n",
                "\n",
                "# Run completeness analysis\n",
                "completeness_results = analyze_completeness(users_df, firms_df, events_df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Event Type Distribution Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "def analyze_event_types(events_df):\n",
                "    \"\"\"Analyze event type distribution.\"\"\"\n",
                "    print(\"\\nüìä Event Type Distribution Analysis\")\n",
                "    print(\"=\" * 50)\n",
                "    \n",
                "    event_type_counts = events_df['event_type'].value_counts()\n",
                "    event_type_pct = (event_type_counts / len(events_df)) * 100\n",
                "    \n",
                "    print(f\"\\nEvent Type Distribution:\")\n",
                "    for event_type, count in event_type_counts.items():\n",
                "        pct = event_type_pct[event_type]\n",
                "        print(f\"   {event_type}: {count} events ({pct:.1f}%)\")\n",
                "    \n",
                "    print(f\"\\nTotal Events: {len(events_df)}\")\n",
                "    print(f\"Unique Event Types: {events_df['event_type'].nunique()}\")\n",
                "    \n",
                "    return event_type_counts\n",
                "\n",
                "# Run event type analysis\n",
                "event_type_results = analyze_event_types(events_df)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create event type visualization\n",
                "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
                "\n",
                "# Bar chart\n",
                "event_type_results.plot(kind='bar', ax=ax1, color='skyblue')\n",
                "ax1.set_title('Event Type Distribution (Bar Chart)', fontsize=14, fontweight='bold')\n",
                "ax1.set_xlabel('Event Type', fontsize=12)\n",
                "ax1.set_ylabel('Number of Events', fontsize=12)\n",
                "ax1.tick_params(axis='x', rotation=45)\n",
                "\n",
                "# Pie chart\n",
                "ax2.pie(event_type_results.values, labels=event_type_results.index, autopct='%1.1f%%', startangle=90)\n",
                "ax2.set_title('Event Type Distribution (Pie Chart)', fontsize=14, fontweight='bold')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Data Consistency Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "def analyze_consistency(users_df, firms_df, events_df):\n",
                "    \"\"\"Analyze data consistency issues.\"\"\"\n",
                "    print(\"\\nüîç Data Consistency Analysis\")\n",
                "    print(\"=\" * 50)\n",
                "    \n",
                "    # Feedback score range check\n",
                "    feedback_min = events_df['feedback_score'].min()\n",
                "    feedback_max = events_df['feedback_score'].max()\n",
                "    print(f\"\\nüìä Feedback Score Range:\")\n",
                "    print(f\"   Expected: 1-5\")\n",
                "    print(f\"   Actual: {feedback_min}-{feedback_max}\")\n",
                "    print(f\"   Status: {'‚úÖ Valid' if feedback_min >= 1 and feedback_max <= 5 else '‚ùå Invalid'}\")\n",
                "    \n",
                "    # Document count range check\n",
                "    docs_min = events_df['num_docs'].min()\n",
                "    docs_max = events_df['num_docs'].max()\n",
                "    print(f\"\\nüìÑ Document Count Range:\")\n",
                "    print(f\"   Expected: >= 0\")\n",
                "    print(f\"   Actual: {docs_min}-{docs_max}\")\n",
                "    print(f\"   Status: {'‚úÖ Valid' if docs_min >= 0 else '‚ùå Invalid'}\")\n",
                "    \n",
                "    # Date consistency check\n",
                "    events_df['created_at'] = pd.to_datetime(events_df['created_at'])\n",
                "    users_df['created_at'] = pd.to_datetime(users_df['created_at'])\n",
                "    \n",
                "    # Check if any events occur before user creation\n",
                "    merged_df = events_df.merge(users_df[['user_id', 'created_at']], on='user_id', suffixes=('_event', '_user'))\n",
                "    events_before_user = merged_df[merged_df['created_at_event'] < merged_df['created_at_user']]\n",
                "    \n",
                "    print(f\"\\nüìÖ Date Consistency:\")\n",
                "    print(f\"   Events before user creation: {len(events_before_user)} records\")\n",
                "    print(f\"   Status: {'‚úÖ Valid' if len(events_before_user) == 0 else '‚ùå Invalid'}\")\n",
                "    \n",
                "    return {\n",
                "        'feedback_range': (feedback_min, feedback_max),\n",
                "        'docs_range': (docs_min, docs_max),\n",
                "        'events_before_user': len(events_before_user)\n",
                "    }\n",
                "\n",
                "# Run consistency analysis\n",
                "consistency_results = analyze_consistency(users_df, firms_df, events_df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Business Logic Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "def analyze_business_logic(users_df, firms_df, events_df):\n",
                "    \"\"\"Analyze business logic violations.\"\"\"\n",
                "    print(\"\\nüîç Business Logic Analysis\")\n",
                "    print(\"=\" * 50)\n",
                "    \n",
                "    # Check for firms with zero ARR\n",
                "    zero_arr_firms = firms_df[firms_df['arr'] == 0]\n",
                "    print(f\"\\nüí∞ Firms with Zero ARR:\")\n",
                "    print(f\"   Count: {len(zero_arr_firms)} firms\")\n",
                "    print(f\"   Status: {'‚úÖ Valid' if len(zero_arr_firms) == 0 else '‚ùå Invalid'}\")\n",
                "    \n",
                "    # Check for firms with zero employees\n",
                "    zero_emp_firms = firms_df[firms_df['num_employees'] == 0]\n",
                "    print(f\"\\nüë• Firms with Zero Employees:\")\n",
                "    print(f\"   Count: {len(zero_emp_firms)} firms\")\n",
                "    print(f\"   Status: {'‚úÖ Valid' if len(zero_emp_firms) == 0 else '‚ùå Invalid'}\")\n",
                "    \n",
                "    # Check for future dates\n",
                "    current_date = pd.Timestamp.now()\n",
                "    future_events = events_df[pd.to_datetime(events_df['created_at']) > current_date]\n",
                "    print(f\"\\nüìÖ Future Date Events:\")\n",
                "    print(f\"   Count: {len(future_events)} events\")\n",
                "    print(f\"   Status: {'‚úÖ Valid' if len(future_events) == 0 else '‚ùå Invalid'}\")\n",
                "    \n",
                "    # Check for valid user titles\n",
                "    valid_titles = ['Associate', 'Partner', 'Counsel', 'Of Counsel', 'Paralegal', 'Legal Assistant']\n",
                "    invalid_titles = users_df[~users_df['title'].isin(valid_titles)]\n",
                "    print(f\"\\nüëî Invalid User Titles:\")\n",
                "    print(f\"   Count: {len(invalid_titles)} users\")\n",
                "    print(f\"   Status: {'‚úÖ Valid' if len(invalid_titles) == 0 else '‚ùå Invalid'}\")\n",
                "    \n",
                "    return {\n",
                "        'zero_arr_firms': len(zero_arr_firms),\n",
                "        'zero_emp_firms': len(zero_emp_firms),\n",
                "        'future_events': len(future_events),\n",
                "        'invalid_titles': len(invalid_titles)\n",
                "    }\n",
                "\n",
                "# Run business logic analysis\n",
                "business_logic_results = analyze_business_logic(users_df, firms_df, events_df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Anomaly Detection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "def analyze_anomalies(users_df, firms_df, events_df):\n",
                "    \"\"\"Analyze statistical anomalies.\"\"\"\n",
                "    print(\"\\nüîç Anomaly Detection Analysis\")\n",
                "    print(\"=\" * 50)\n",
                "    \n",
                "    # Feedback score outliers using IQR method\n",
                "    feedback_scores = events_df['feedback_score'].dropna()\n",
                "    Q1 = feedback_scores.quantile(0.25)\n",
                "    Q3 = feedback_scores.quantile(0.75)\n",
                "    IQR = Q3 - Q1\n",
                "    lower_bound = Q1 - 1.5 * IQR\n",
                "    upper_bound = Q3 + 1.5 * IQR\n",
                "    \n",
                "    feedback_outliers = events_df[(events_df['feedback_score'] < lower_bound) | \n",
                "                                   (events_df['feedback_score'] > upper_bound)]\n",
                "    \n",
                "    print(f\"\\nüìä Feedback Score Outliers (IQR Method):\")\n",
                "    print(f\"   Q1: {Q1:.2f}, Q3: {Q3:.2f}, IQR: {IQR:.2f}\")\n",
                "    print(f\"   Lower Bound: {lower_bound:.2f}, Upper Bound: {upper_bound:.2f}\")\n",
                "    print(f\"   Outliers: {len(feedback_outliers)} events ({len(feedback_outliers)/len(events_df)*100:.1f}%)\")\n",
                "    \n",
                "    # Document count outliers\n",
                "    doc_counts = events_df['num_docs'].dropna()\n",
                "    Q1_docs = doc_counts.quantile(0.25)\n",
                "    Q3_docs = doc_counts.quantile(0.75)\n",
                "    IQR_docs = Q3_docs - Q1_docs\n",
                "    upper_bound_docs = Q3_docs + 1.5 * IQR_docs\n",
                "    \n",
                "    doc_outliers = events_df[events_df['num_docs'] > upper_bound_docs]\n",
                "    \n",
                "    print(f\"\\nüìÑ Document Count Outliers (IQR Method):\")\n",
                "    print(f\"   Q1: {Q1_docs:.2f}, Q3: {Q3_docs:.2f}, IQR: {IQR_docs:.2f}\")\n",
                "    print(f\"   Upper Bound: {upper_bound_docs:.2f}\")\n",
                "    print(f\"   Outliers: {len(doc_outliers)} events ({len(doc_outliers)/len(events_df)*100:.1f}%)\")\n",
                "    \n",
                "    # Calculate overall anomaly percentage\n",
                "    total_anomalies = len(feedback_outliers) + len(doc_outliers)\n",
                "    total_records = len(events_df)\n",
                "    anomaly_percentage = (total_anomalies / total_records) * 100\n",
                "    \n",
                "    print(f\"\\nüìà Overall Anomaly Summary:\")\n",
                "    print(f\"   Total Anomalies: {total_anomalies} events\")\n",
                "    print(f\"   Total Records: {total_records} events\")\n",
                "    print(f\"   Anomaly Percentage: {anomaly_percentage:.1f}%\")\n",
                "    \n",
                "    return {\n",
                "        'feedback_outliers': len(feedback_outliers),\n",
                "        'doc_outliers': len(doc_outliers),\n",
                "        'total_anomalies': total_anomalies,\n",
                "        'anomaly_percentage': anomaly_percentage\n",
                "    }\n",
                "\n",
                "# Run anomaly analysis\n",
                "anomaly_results = analyze_anomalies(users_df, firms_df, events_df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Create Visualizations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_visualizations(users_df, firms_df, events_df, analysis_results):\n",
                "    \"\"\"Create comprehensive visualizations for data quality analysis.\"\"\"\n",
                "    \n",
                "    # Create subplots\n",
                "    fig = make_subplots(\n",
                "        rows=2, cols=2,\n",
                "        subplot_titles=('Missing Values Analysis', 'Business Logic Analysis', \n",
                "                       'Feedback Score Distribution', 'Document Count Distribution'),\n",
                "        specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}],\n",
                "               [{\"type\": \"histogram\"}, {\"type\": \"histogram\"}]]\n",
                "    )\n",
                "    \n",
                "    # 1. Missing Values Analysis\n",
                "    missing_data = {\n",
                "        'Users': completeness_results['users_missing'].sum(),\n",
                "        'Firms': completeness_results['firms_missing'].sum(),\n",
                "        'Events': completeness_results['events_missing'].sum()\n",
                "    }\n",
                "    \n",
                "    fig.add_trace(\n",
                "        go.Bar(x=list(missing_data.keys()), y=list(missing_data.values()), \n",
                "               name='Missing Values', marker_color='lightcoral'),\n",
                "        row=1, col=1\n",
                "    )\n",
                "    \n",
                "    # 2. Business Logic Analysis\n",
                "    business_logic_data = {\n",
                "        'Zero ARR Firms': business_logic_results['zero_arr_firms'],\n",
                "        'Zero Employees': business_logic_results['zero_emp_firms'],\n",
                "        'Future Events': business_logic_results['future_events'],\n",
                "        'Invalid Titles': business_logic_results['invalid_titles']\n",
                "    }\n",
                "    \n",
                "    fig.add_trace(\n",
                "        go.Bar(x=list(business_logic_data.keys()), y=list(business_logic_data.values()), \n",
                "               name='Business Logic Issues', marker_color='lightblue'),\n",
                "        row=1, col=2\n",
                "    )\n",
                "    \n",
                "    # 3. Feedback Score Distribution\n",
                "    fig.add_trace(\n",
                "        go.Histogram(x=events_df['feedback_score'], nbinsx=10, name='Feedback Scores', \n",
                "                     marker_color='lightgreen'),\n",
                "        row=2, col=1\n",
                "    )\n",
                "    \n",
                "    # 4. Document Count Distribution\n",
                "    fig.add_trace(\n",
                "        go.Histogram(x=events_df['num_docs'], nbinsx=20, name='Document Counts', \n",
                "                     marker_color='lightyellow'),\n",
                "        row=2, col=2\n",
                "    )\n",
                "    \n",
                "    # Update layout\n",
                "    fig.update_layout(\n",
                "        title_text=\"Harvey Data Quality Analysis Dashboard\",\n",
                "        height=800,\n",
                "        showlegend=False\n",
                "    )\n",
                "    \n",
                "    fig.show()\n",
                "    \n",
                "    return fig\n",
                "\n",
                "# Create visualizations\n",
                "analysis_results = {\n",
                "    'completeness': completeness_results,\n",
                "    'consistency': consistency_results,\n",
                "    'business_logic': business_logic_results,\n",
                "    'anomalies': anomaly_results\n",
                "}\n",
                "\n",
                "viz_fig = create_visualizations(users_df, firms_df, events_df, analysis_results)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Generate Summary Report"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_summary_report(users_df, firms_df, events_df, analysis_results):\n",
                "    \"\"\"Generate a comprehensive summary report.\"\"\"\n",
                "    print(\"\\nüìã Data Quality Analysis Summary Report\")\n",
                "    print(\"=\" * 60)\n",
                "    \n",
                "    # Calculate overall data quality score\n",
                "    total_issues = 0\n",
                "    total_checks = 0\n",
                "    \n",
                "    # Completeness checks\n",
                "    completeness_issues = (completeness_results['users_missing'].sum() + \n",
                "                          completeness_results['firms_missing'].sum() + \n",
                "                          completeness_results['events_missing'].sum())\n",
                "    total_issues += completeness_issues\n",
                "    total_checks += 3\n",
                "    \n",
                "    # Consistency checks\n",
                "    consistency_issues = 0\n",
                "    if consistency_results['feedback_range'][0] < 1 or consistency_results['feedback_range'][1] > 5:\n",
                "        consistency_issues += 1\n",
                "    if consistency_results['docs_range'][0] < 0:\n",
                "        consistency_issues += 1\n",
                "    if consistency_results['events_before_user'] > 0:\n",
                "        consistency_issues += 1\n",
                "    total_issues += consistency_issues\n",
                "    total_checks += 3\n",
                "    \n",
                "    # Business logic checks\n",
                "    business_logic_issues = (business_logic_results['zero_arr_firms'] + \n",
                "                            business_logic_results['zero_emp_firms'] + \n",
                "                            business_logic_results['future_events'] + \n",
                "                            business_logic_results['invalid_titles'])\n",
                "    total_issues += business_logic_issues\n",
                "    total_checks += 4\n",
                "    \n",
                "    # Calculate quality score\n",
                "    quality_score = ((total_checks - total_issues) / total_checks) * 100\n",
                "    \n",
                "    print(f\"\\nüìä Overall Data Quality Score: {quality_score:.1f}%\")\n",
                "    print(f\"   Total Checks: {total_checks}\")\n",
                "    print(f\"   Total Issues: {total_issues}\")\n",
                "    \n",
                "    print(f\"\\nüîç Detailed Findings:\")\n",
                "    print(f\"   ‚Ä¢ Completeness Issues: {completeness_issues}\")\n",
                "    print(f\"   ‚Ä¢ Consistency Issues: {consistency_issues}\")\n",
                "    print(f\"   ‚Ä¢ Business Logic Issues: {business_logic_issues}\")\n",
                "    print(f\"   ‚Ä¢ Statistical Anomalies: {anomaly_results['total_anomalies']} events ({anomaly_results['anomaly_percentage']:.1f}%)\")\n",
                "    \n",
                "    print(f\"\\n‚úÖ Recommendations:\")\n",
                "    if completeness_issues > 0:\n",
                "        print(f\"   ‚Ä¢ Address missing values in data sources\")\n",
                "    if consistency_issues > 0:\n",
                "        print(f\"   ‚Ä¢ Implement data validation rules\")\n",
                "    if business_logic_issues > 0:\n",
                "        print(f\"   ‚Ä¢ Review and fix business logic violations\")\n",
                "    if anomaly_results['anomaly_percentage'] > 10:\n",
                "        print(f\"   ‚Ä¢ Investigate statistical anomalies (consider adjusting thresholds)\")\n",
                "    \n",
                "    if quality_score >= 90:\n",
                "        print(f\"\\nüéâ Data quality is excellent!\")\n",
                "    elif quality_score >= 80:\n",
                "        print(f\"\\nüëç Data quality is good with minor issues.\")\n",
                "    elif quality_score >= 70:\n",
                "        print(f\"\\n‚ö†Ô∏è Data quality needs attention.\")\n",
                "    else:\n",
                "        print(f\"\\n‚ùå Data quality requires immediate attention.\")\n\n",
                "\n",
                "# Generate summary report\n",
                "generate_summary_report(users_df, firms_df, events_df, analysis_results)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}

# Write the notebook to file
with open('harvey_data_quality_analysis.ipynb', 'w') as f:
    json.dump(notebook, f, indent=2)

print("‚úÖ Complete Jupyter notebook created successfully!")
print("File: harvey_data_quality_analysis.ipynb") 